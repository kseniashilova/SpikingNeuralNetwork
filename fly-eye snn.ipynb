{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch==1.10.1 torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from SpykeTorch import snn\n",
    "from SpykeTorch import functional as sf\n",
    "from SpykeTorch import visualization as vis\n",
    "from SpykeTorch import utils\n",
    "from torchvision import transforms\n",
    "\n",
    "#use_cuda = True\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlyEye(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlyEye, self).__init__()\n",
    "\n",
    "        # photoreceptor cells\n",
    "        #self.R1_6 = snn.Convolution(1,1,1)\n",
    "        self.convR7 = snn.Convolution(6,1,1)\n",
    "        self.convR8 = snn.Convolution(1,1,1)\n",
    "        \n",
    "        self.convR7_t = 10\n",
    "        self.convR8_t = 10\n",
    "        # Lamina\n",
    "        self.convL1 = snn.Convolution(1,1,1)\n",
    "        self.convL2 = snn.Convolution(1,1,1)\n",
    "        self.convL3 = snn.Convolution(1,1,1)\n",
    "        self.convL4 = snn.Convolution(1,1,1)\n",
    "        self.convL5 = snn.Convolution(1,1,1)\n",
    "        \n",
    "        self.convC2 = snn.Convolution(1,1,1)\n",
    "        self.convC3 = snn.Convolution(1,1,1)\n",
    "        \n",
    "        self.convL1_t = 10\n",
    "        self.convL2_t = 10\n",
    "        self.convL3_t = 10\n",
    "        self.convL4_t = 10\n",
    "        self.convL5_t = 10\n",
    "        self.convC2_t = 10\n",
    "        self.convC3_t = 10\n",
    "        \n",
    "        # Medulla\n",
    "        self.convMi1 = snn.Convolution(1,1,1)\n",
    "        self.convMi4 = snn.Convolution(1,1,1)\n",
    "        self.convMi9 = snn.Convolution(1,1,1)\n",
    "        self.convMi15 = snn.Convolution(1,1,1)\n",
    "        \n",
    "        self.convTm1 = snn.Convolution(1,1,1)\n",
    "        self.convTm2 = snn.Convolution(1,1,1)\n",
    "        self.convTm3 = snn.Convolution(1,1,1)\n",
    "        self.convTm4 = snn.Convolution(1,1,1)\n",
    "        self.convTm6 = snn.Convolution(1,1,1)\n",
    "        self.convTm9 = snn.Convolution(1,1,1)\n",
    "        self.convTm20 = snn.Convolution(1,1,1)\n",
    "        self.convTmY5a = snn.Convolution(1,1,1)\n",
    "        \n",
    "        self.convT2 = snn.Convolution(1,1,1)\n",
    "        self.convT2a = snn.Convolution(1,1,1)\n",
    "        self.convT3 = snn.Convolution(1,1,1)\n",
    "        \n",
    "        self.convMi1_t = 10\n",
    "        self.convMi4_t = 10\n",
    "        self.convMi9_t = 10\n",
    "        self.convMi15_t = 10\n",
    "        self.convTm1_t = 10\n",
    "        self.convTm2_t = 10\n",
    "        self.convTm3_t = 10\n",
    "        self.convTm4_t = 10\n",
    "        self.convTm6_t = 10\n",
    "        self.convTm9_t = 10\n",
    "        self.convTm20_t = 10\n",
    "        self.convTmY5a_t = 10\n",
    "        self.convTmT2_t = 10\n",
    "        self.convTmT2a_t = 10\n",
    "        self.convTmT3_t = 10\n",
    "        \n",
    "        # Lobula\n",
    "        self.convLC4 = snn.Convolution(1,1,1)\n",
    "        self.convLC17 = snn.Convolution(1,1,1)\n",
    "        \n",
    "        self.convLC4_t = 10\n",
    "        self.convLC17_t = 10\n",
    "        \n",
    "        # Cenral brain\n",
    "        self.convCB = snn.Convolution(1,1,1)\n",
    "        #self.convCB_t = inf\n",
    "        \n",
    "        # STDP applying\n",
    "        #self.stdpR1_6 = snn.STDP(self.convR1_6, (0.004, -0.003))\n",
    "        self.stdpR7 = snn.STDP(self.convR7, (0.004, -0.003))\n",
    "        self.stdpR8 = snn.STDP(self.convR8, (0.004, -0.003))        \n",
    "        \n",
    "        self.stdpL1 = snn.STDP(self.convL1, (0.004, -0.003))\n",
    "        self.stdpL2 = snn.STDP(self.convL2, (0.004, -0.003))\n",
    "        self.stdpL3 = snn.STDP(self.convL3, (0.004, -0.003))\n",
    "        self.stdpL4 = snn.STDP(self.convL4, (0.004, -0.003))\n",
    "        self.stdpL5 = snn.STDP(self.convL5, (0.004, -0.003))\n",
    "        \n",
    "        self.stdpC2 = snn.STDP(self.convC2, (0.004, -0.003))\n",
    "        self.stdpC3 = snn.STDP(self.convC3, (0.004, -0.003))\n",
    "        \n",
    "        self.stdpMi1 = snn.STDP(self.convMi1, (0.004, -0.003))\n",
    "        self.stdpMi14 = snn.STDP(self.convMi4, (0.004, -0.003))\n",
    "        self.stdpMi9 = snn.STDP(self.convMi9, (0.004, -0.003))\n",
    "        self.stdpMi15 = snn.STDP(self.convMi15, (0.004, -0.003))\n",
    "        \n",
    "        self.stdpTm1 = snn.STDP(self.convTm1, (0.004, -0.003))\n",
    "        self.stdpTm2 = snn.STDP(self.convTm2, (0.004, -0.003))\n",
    "        self.stdpTm3 = snn.STDP(self.convTm3, (0.004, -0.003))\n",
    "        self.stdpTm4 = snn.STDP(self.convTm4, (0.004, -0.003))\n",
    "        self.stdpTm6 = snn.STDP(self.convTm6, (0.004, -0.003))\n",
    "        self.stdpTm9 = snn.STDP(self.convTm9, (0.004, -0.003))\n",
    "        self.stdpTm20 = snn.STDP(self.convTm20, (0.004, -0.003))\n",
    "        self.stdpTmY5a = snn.STDP(self.convTmY5a, (0.004, -0.003))\n",
    "        \n",
    "        self.stdpT2 = snn.STDP(self.convT2, (0.004, -0.003))\n",
    "        self.stdpT2a = snn.STDP(self.convT2a, (0.004, -0.003))\n",
    "        self.stdpT3 = snn.STDP(self.convT3, (0.004, -0.003))\n",
    "        \n",
    "        self.stdpLC4 = snn.STDP(self.convLC4, (0.004, -0.003))\n",
    "        self.stdpLC17 = snn.STDP(self.convLC17, (0.004, -0.003))\n",
    "        \n",
    "        self.anti_stdp_central_brain = snn.STDP(self.convCB, (-0.004, 0.005), False, 0.2, 0.8)\n",
    "        self.stdp_central_brain = snn.STDP(self.convCB, (0.004, -0.003), False, 0.2, 0.8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.ctx = {\"input_spikes\":None, \"potentials\":None, \"output_spikes\":None, \"winners\":None}\n",
    "        self.spk_cnt1 = 0\n",
    "        self.spk_cnt2 = 0\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, input, max_layer):\n",
    "        # input - данные после обработки\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # R1_6, R7, R8-------------------------------------------------------------------------------------------------\n",
    "        R1_6 = input\n",
    "\n",
    "        potR7 = self.convR7(input)\n",
    "        spkR7, potR7 = sf.fire(potR7, self.convR7_t, True)\n",
    "\n",
    "        if max_layer == 'R7':\n",
    "            pot = sf.pointwise_inhibition(potR7)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = input\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        potR8 = self.convR8(input)\n",
    "        spkR8, potR8 = sf.fire(potR8, self.convR8_t, True)\n",
    "        \n",
    "        if max_layer == 'R8':\n",
    "            pot = sf.pointwise_inhibition(potR8)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = input\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # L1, L2, L3, L4, L5------------------------------------------------------------------------------------------\n",
    "        # L1: R1_6 + R8 as input\n",
    "        potL1 = self.convL1(torch.cat([R1_6,spkR8], dim=1))\n",
    "        spkL1, potL1 = sf.fire(potL1, self.convL1_t, True)\n",
    "        if max_layer == 'L1':\n",
    "            pot = sf.pointwise_inhibition(potL1)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([R1_6,spkR8], dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "                                                 \n",
    "        # L2: R1_6 as input\n",
    "        potL2 = self.convL2(R1_6)\n",
    "        spkL2, potL2 = sf.fire(potL2, self.convL2_t, True)\n",
    "        if max_layer == 'L2':\n",
    "            pot = sf.pointwise_inhibition(potL2)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = R1_6\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "                                                 \n",
    "        # L3: R1_6, R7, R8 as input\n",
    "        potL3 = self.convL3(torch.cat([R1_6,spkR7,spkR8], dim=1))\n",
    "        spkL3, potL3 = sf.fire(potL3, self.convL3_t, True)\n",
    "        if max_layer == 'L3':\n",
    "            pot = sf.pointwise_inhibition(potL3)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([R1_6,spkR7,spkR8], dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "                                                 \n",
    "        # L4: R1_6 as input\n",
    "        potL4 = self.convL4(R1_6)\n",
    "        spkL4, potL4 = sf.fire(potL4, self.convL4_t, True)\n",
    "        if max_layer == 'L4':\n",
    "            pot = sf.pointwise_inhibition(potL4)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = R1_6\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        # L5: R1_6 + R8 as input\n",
    "        potL5 = self.convL5(torch.cat([R1_6,spkR8], dim=1))\n",
    "        spkL5, potL5 = sf.fire(potL5, self.convL5_t, True)\n",
    "        if max_layer == 'L5':\n",
    "            pot = sf.pointwise_inhibition(potL5)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([R1_6,spkR8], dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot                                         \n",
    "    \n",
    "\n",
    "        # C2, C3------------------------------------------------------------------------------------------------------\n",
    "        # C2: L1, L5(5,5) as input\n",
    "        potC2 = self.convC2(torch.cat([spkL1,\n",
    "                                       sf.pooling(spkL5, 5, 1, 2)],\n",
    "                                      dim=1))\n",
    "        spkC2, potC2 = sf.fire(potC2, self.convC2_t, True)\n",
    "        if max_layer == 'C2':\n",
    "            pot = sf.pointwise_inhibition(potC2)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkL1,\n",
    "                                       sf.pooling(spkL5, 5, 1, 2)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        # C3: L1, L2, L3, L5(3,3) as input\n",
    "        potC3 = self.convC3(torch.cat([spkL1, spkL2, spkL3,\n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkC3, potC3 = sf.fire(potC3, self.convC3_t, True)\n",
    "        if max_layer == 'C3':\n",
    "            pot = sf.pointwise_inhibition(potC3)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkL1, spkL2, spkL3,\n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # Mi1, Mi4, Mi9, Mi15-----------------------------------------------------------------------------------------\n",
    "        # Mi1: R8, L1, L3, C2, C3, L5(3,3) as input\n",
    "        potMi1 = self.convMi1(torch.cat([spkR8, spkL1, spkL3,spkC2,spkC3,\n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkMi1, potMi1 = sf.fire(potMi1, self.convMi1_t, True)\n",
    "        if max_layer == 'Mi1':\n",
    "            pot = sf.pointwise_inhibition(potMi1)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkR8, spkL1, spkL3,spkC2,spkC3,\n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # Mi4: R8, L2, L3, C2, C3, L5(3,3) as input\n",
    "        potMi4 = self.convMi4(torch.cat([spkR8, spkL2, spkL3,spkC2,spkC3, \n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkMi4, potMi4 = sf.fire(potMi4, self.convMi4_t, True)\n",
    "        if max_layer == 'Mi4':\n",
    "            pot = sf.pointwise_inhibition(potMi4)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkR8, spkL2, spkL3,spkC2,spkC3, \n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        # Mi9: R7, R8, L2, L3(3,3), L4(3,3) as input\n",
    "        potMi9 = self.convMi9(torch.cat([spkR7, spkR8, spkL2, \n",
    "                                       sf.pooling(spkL3, 3, 1, 1),\n",
    "                                       sf.pooling(spkL4, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkMi9, potMi9 = sf.fire(potMi9, self.convMi9_t, True)\n",
    "        if max_layer == 'Mi9':\n",
    "            pot = sf.pointwise_inhibition(potMi9)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkR7, spkR8, spkL2, \n",
    "                                       sf.pooling(spkL3, 3, 1, 1),\n",
    "                                       sf.pooling(spkL4, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        # Mi15: R8(3,3), L5(3,3) as input\n",
    "        potMi15 = self.convMi15(torch.cat([ \n",
    "                                       sf.pooling(spkR8, 3, 1, 1),\n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkMi15, potMi15 = sf.fire(potMi15, self.convMi15_t, True)\n",
    "        if max_layer == 'Mi15':\n",
    "            pot = sf.pointwise_inhibition(potMi15)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([ \n",
    "                                       sf.pooling(spkR8, 3, 1, 1),\n",
    "                                       sf.pooling(spkL5, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # Tm1, Tm2, Tm3, Tm4, Tm6, Tm9, Tm20, TmY5a------------------------------------------------------------------\n",
    "        # Tm1: L2, L5, C2, C3, Mi1, Mi4, Mi9\n",
    "        potTm1 = self.convTm1(torch.cat([spkL2, spkL5, spkC2, spkC3,\n",
    "                                         spkMi1, spkMi4, spkMi9],\n",
    "                                      dim=1))\n",
    "        spkTm1, potTm1 = sf.fire(potTm1, self.convTm1_t, True)\n",
    "        if max_layer == 'Tm1':\n",
    "            pot = sf.pointwise_inhibition(potTm1)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkL2, spkL5, spkC2, spkC3,\n",
    "                                         spkMi1, spkMi4, spkMi9],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # Tm2: L2, L4(3,3), C3, Mi1, Mi9\n",
    "        potTm2 = self.convTm2(torch.cat([spkL2, spkC3, spkMi1, spkMi9,\n",
    "                                         sf.pooling(spkL4, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkTm2, potTm2 = sf.fire(potTm2, self.convTm2_t, True)\n",
    "        if max_layer == 'Tm2':\n",
    "            pot = sf.pointwise_inhibition(potTm2)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkL2, spkC3, spkMi1, spkMi9,\n",
    "                                         sf.pooling(spkL4, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        # Tm3: L3(3,3), C2(3,3), Mi4(3,3), Mi9(3,3), L1(5,5), L5(5,5), Mi1(5,5)\n",
    "        potTm3 = self.convTm3(torch.cat([\n",
    "                                         sf.pooling(spkL3, 3, 1, 1),\n",
    "                                         sf.pooling(spkC2, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi9, 3, 1, 1),                \n",
    "                                         sf.pooling(spkL1, 5, 1, 2),\n",
    "                                         sf.pooling(spkL5, 5, 1, 2),\n",
    "                                         sf.pooling(spkMi1, 5, 1, 2)],\n",
    "                                      dim=1))\n",
    "        spkTm3, potTm3 = sf.fire(potTm3, self.convTm3_t, True)\n",
    "        if max_layer == 'Tm3':\n",
    "            pot = sf.pointwise_inhibition(potTm3)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([\n",
    "                                         sf.pooling(spkL3, 3, 1, 1),\n",
    "                                         sf.pooling(spkC2, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi9, 3, 1, 1),                \n",
    "                                         sf.pooling(spkL1, 5, 1, 2),\n",
    "                                         sf.pooling(spkL5, 5, 1, 2),\n",
    "                                         sf.pooling(spkMi1, 5, 1, 2)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # Tm4: L4(3,3), Mi4(3), Mi9(3), L2(5), C3(5)\n",
    "        potTm4 = self.convTm4(torch.cat([\n",
    "                                         sf.pooling(spkL4, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi9, 3, 1, 1),                \n",
    "                                         sf.pooling(spkL2, 5, 1, 2),\n",
    "                                         sf.pooling(spkC3, 5, 1, 2)],\n",
    "                                      dim=1))\n",
    "        spkTm4, potTm4 = sf.fire(potTm4, self.convTm4_t, True)\n",
    "        if max_layer == 'Tm4':\n",
    "            pot = sf.pointwise_inhibition(potTm4)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([\n",
    "                                         sf.pooling(spkL4, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi9, 3, 1, 1),                \n",
    "                                         sf.pooling(spkL2, 5, 1, 2),\n",
    "                                         sf.pooling(spkC3, 5, 1, 2)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # Tm6: Mi1(3), Mi15(3), L5(5), Mi9(5)\n",
    "        potTm6 = self.convTm6(torch.cat([sf.pooling(spkMi1, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi15, 3, 1, 1),               \n",
    "                                         sf.pooling(spkL5, 5, 1, 2),\n",
    "                                         sf.pooling(spkMi9, 5, 1, 2)],\n",
    "                                      dim=1))\n",
    "        spkTm6, potTm6 = sf.fire(potTm6, self.convTm6_t, True)\n",
    "        if max_layer == 'Tm6':\n",
    "            pot = sf.pointwise_inhibition(potTm6)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkMi1, 3, 1, 1),\n",
    "                                         sf.pooling(spkMi15, 3, 1, 1),               \n",
    "                                         sf.pooling(spkL5, 5, 1, 2),\n",
    "                                         sf.pooling(spkMi9, 5, 1, 2)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        # Tm9: L4(3), Mi4(3), L2, C2, C3\n",
    "        potTm9 = self.convTm9(torch.cat([sf.pooling(spkL4, 3, 1, 1),\n",
    "                                        sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                        spkL2, spkC2, spkC3],\n",
    "                                      dim=1))\n",
    "        spkTm9, potTm9 = sf.fire(potTm9, self.convTm9_t, True)\n",
    "        if max_layer == 'Tm9':\n",
    "            pot = sf.pointwise_inhibition(potTm9)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkL4, 3, 1, 1),\n",
    "                                        sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                        spkL2, spkC2, spkC3],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        # Tm20: Mi4(3), R7, R8, L2, C3, Mi1\n",
    "        potTm20 = self.convTm20(torch.cat([sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                        spkR7, spkR8, spkL2, spkC3, spkMi1],\n",
    "                                      dim=1))\n",
    "        spkTm20, potTm20 = sf.fire(potTm20, self.convTm20_t, True)\n",
    "        if max_layer == 'Tm20':\n",
    "            pot = sf.pointwise_inhibition(potTm20)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                        spkR7, spkR8, spkL2, spkC3, spkMi1],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # TmY5a: L5(3), Mi4(3), Mi9(3)\n",
    "        potTmY5a = self.convTmY5a(torch.cat([sf.pooling(spkL5, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi9, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkTmY5a, potTmY5a = sf.fire(potTmY5a, self.convTmY5a_t, True)\n",
    "        if max_layer == 'TmY5a':\n",
    "            pot = sf.pointwise_inhibition(potTmY5a)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkL5, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi4, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi9, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "\n",
    "        # T2, T2a, T3-----------------------------------------------------------------------------------------------\n",
    "        # T2: Mi1(3), Tm1(3), Tm3(3), Tm4(3), TmY5a(3)\n",
    "        potT2 = self.convT2(torch.cat([sf.pooling(spkMi1, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm1, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm3, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm4, 3, 1, 1),\n",
    "                                            sf.pooling(spkTmY5a, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkT2, potT2 = sf.fire(potT2, self.convT2_t, True)\n",
    "        if max_layer == 'T2':\n",
    "            pot = sf.pointwise_inhibition(potT2)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkMi1, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm1, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm3, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm4, 3, 1, 1),\n",
    "                                            sf.pooling(spkTmY5a, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # T2a: L2, L5, C2, C3, Mi4, Tm1, Tm2\n",
    "        potT2a = self.convT2a(torch.cat([spkL2, spkL5, spkC2, spkC3, spkMi4, spkTm1, spkTm2], dim=1))\n",
    "        spkT2a, potT2a = sf.fire(potT2a, self.convT2a_t, True)\n",
    "        if max_layer == 'T2a':\n",
    "            pot = sf.pointwise_inhibition(potT2a)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkL2, spkL5, spkC2, spkC3, spkMi4, spkTm1, spkTm2], dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # T3: L2, L4, L5, C2, C3, Mi1, Mi9, Tm1, Tm2, Tm3, Tm6, TmY5a - 3 window\n",
    "        potT3 = self.convT3(torch.cat([sf.pooling(spkL2, 3, 1, 1),\n",
    "                                            sf.pooling(spkL4, 3, 1, 1),\n",
    "                                            sf.pooling(spkL5, 3, 1, 1),\n",
    "                                            sf.pooling(spkC2, 3, 1, 1),\n",
    "                                            sf.pooling(spkC3, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi1, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi9, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm1, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm2, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm3, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm6, 3, 1, 1),\n",
    "                                            sf.pooling(spkTmY5a, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkT3, potT3 = sf.fire(potT3, self.convT3_t, True)\n",
    "        if max_layer == 'T3':\n",
    "            pot = sf.pointwise_inhibition(potT3)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkL2, 3, 1, 1),\n",
    "                                            sf.pooling(spkL4, 3, 1, 1),\n",
    "                                            sf.pooling(spkL5, 3, 1, 1),\n",
    "                                            sf.pooling(spkC2, 3, 1, 1),\n",
    "                                            sf.pooling(spkC3, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi1, 3, 1, 1),\n",
    "                                            sf.pooling(spkMi9, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm1, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm2, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm3, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm6, 3, 1, 1),\n",
    "                                            sf.pooling(spkTmY5a, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "\n",
    "        # LC4, LC17------------------------------------------------------------------------------------------------\n",
    "        # LC4: Tm1, Tm2, Tm3, Tm4, Tm6, Tm9, TmY5a, T2, T2a, T3 - 5 window\n",
    "        potLC4 = self.convLC4(torch.cat([sf.pooling(spkTm1, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm2, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm3, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm4, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm6, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm9, 5, 1, 2),\n",
    "                                            sf.pooling(spkTmY5a, 5, 1, 2),\n",
    "                                            sf.pooling(spkT2, 5, 1, 2),\n",
    "                                            sf.pooling(spkT2a, 5, 1, 2),\n",
    "                                            sf.pooling(spkT3, 5, 1, 2)],\n",
    "                                      dim=1))\n",
    "        spkLC4, potLC4 = sf.fire(potLC4, self.convLC4_t, True)\n",
    "        if max_layer == 'LC4':\n",
    "            pot = sf.pointwise_inhibition(potLC4)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkTm1, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm2, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm3, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm4, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm6, 5, 1, 2),\n",
    "                                            sf.pooling(spkTm9, 5, 1, 2),\n",
    "                                            sf.pooling(spkTmY5a, 5, 1, 2),\n",
    "                                            sf.pooling(spkT2, 5, 1, 2),\n",
    "                                            sf.pooling(spkT2a, 5, 1, 2),\n",
    "                                            sf.pooling(spkT3, 5, 1, 2)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "        \n",
    "        \n",
    "        # LC17: Tm2, Tm3, Tm4, Tm6, Tm9, Tm20, TmY5a, T2, T2a, T3 - 3 window\n",
    "        potLC17 = self.convLC17(torch.cat([sf.pooling(spkTm2, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm3, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm4, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm6, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm9, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm20, 3, 1, 1),\n",
    "                                            sf.pooling(spkTmY5a, 3, 1, 1),\n",
    "                                            sf.pooling(spkT2, 3, 1, 1),\n",
    "                                            sf.pooling(spkT2a, 3, 1, 1),\n",
    "                                            sf.pooling(spkT3, 3, 1, 1)],\n",
    "                                      dim=1))\n",
    "        spkLC17, potLC17 = sf.fire(potLC17, self.convLC17_t, True)\n",
    "        if max_layer == 'LC17':\n",
    "            pot = sf.pointwise_inhibition(potLC17)\n",
    "            spk = pot.sign()\n",
    "            winners = sf.get_k_winners(pot, spikes=spk)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([sf.pooling(spkTm2, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm3, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm4, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm6, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm9, 3, 1, 1),\n",
    "                                            sf.pooling(spkTm20, 3, 1, 1),\n",
    "                                            sf.pooling(spkTmY5a, 3, 1, 1),\n",
    "                                            sf.pooling(spkT2, 3, 1, 1),\n",
    "                                            sf.pooling(spkT2a, 3, 1, 1),\n",
    "                                            sf.pooling(spkT3, 3, 1, 1)],\n",
    "                                      dim=1)\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            return spk, pot\n",
    "\n",
    "        # central brain---------------------------------------------------------------------------------------------\n",
    "        potCB = self.convCB(torch.cat([spkLC4, spkLC17],\n",
    "                                      dim=1))\n",
    "        spkCB, potCB = sf.fire(potCB)\n",
    "\n",
    "        \n",
    "        \n",
    "        #------------------------------------------------------------------------------------------------------------\n",
    "        if self.training:    \n",
    "            # finish training\n",
    "            winners = sf.get_k_winners(potCB, 1, 0, spkCB)\n",
    "            self.ctx[\"input_spikes\"] = torch.cat([spkLC4, spkLC17],\n",
    "                                          dim=1)\n",
    "            self.ctx[\"potentials\"] = potCB\n",
    "            self.ctx[\"output_spikes\"] = spkCB\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return outputs\n",
    "        else:\n",
    "            winners = sf.get_k_winners(potCB, 1, 0, spkCB)\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # STDP for layer layer_idx\n",
    "    def stdp(self, layer_idx):\n",
    "        \n",
    "        if layer_idx == 'R7':\n",
    "            self.stdpR7(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'R8':\n",
    "            self.stdpR8(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "       \n",
    "        if layer_idx == 'L1':\n",
    "            self.stdpL1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'L2':\n",
    "            self.stdpL2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'L3':\n",
    "            self.stdpL3(sezf.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'L4':\n",
    "            self.stdpL4(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'L5':\n",
    "            self.stdpL5(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        \n",
    "        if layer_idx == 'C2':\n",
    "            self.stdpC2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'C3':\n",
    "            self.stdpC3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        \n",
    "        if layer_idx == 'Mi1':\n",
    "            self.stdpMi1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Mi4':\n",
    "            self.stdpMi4(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Mi9':\n",
    "            self.stdpMi9(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Mi15':\n",
    "            self.stdpMi15(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        \n",
    "        if layer_idx == 'Tm1':\n",
    "            self.stdpTm1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Tm2':\n",
    "            self.stdpTm2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Tm3':\n",
    "            self.stdpTm3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Tm4':\n",
    "            self.stdpTm4(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Tm6':\n",
    "            self.stdpTm6(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Tm9':\n",
    "            self.stdpTm9(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'Tm20':\n",
    "            self.stdpTm20(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'TmY5a':\n",
    "            self.stdpTmY5a(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "            \n",
    "        if layer_idx == 'T2':\n",
    "            self.stdpT2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'T2a':\n",
    "            self.stdpT2a(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'T3':\n",
    "            self.stdpT3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        \n",
    "        if layer_idx == 'LC4':\n",
    "            self.stdpLC4(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 'LC17':\n",
    "            self.stdpLC17(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "       \n",
    "\n",
    "    # learning rates updating\n",
    "    def update_learning_rates(self, stdp_ap, stdp_an, anti_stdp_ap, anti_stdp_an):\n",
    "        self.stdp_central_brain.update_all_learning_rate(stdp_ap, stdp_an)\n",
    "        self.anti_stdp_central_brain.update_all_learning_rate(anti_stdp_an, anti_stdp_ap)\n",
    "\n",
    "    # reward signal for ultimate layer\n",
    "    def reward(self):\n",
    "        self.stdp_central_brain(\n",
    "            self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "    \n",
    "    # punishment signal for ultimate layer\n",
    "    def punish(self):\n",
    "        self.anti_stdp_central_brain(\n",
    "            self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process for the layer layer_idx (R1_6, R7, R8, L1, L2, L3, .....)\n",
    "def train_unsupervise(network, data, layer_idx):\n",
    "    network.train()\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        network(data_in, layer_idx)\n",
    "        network.stdp(layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rl(network, data, target):\n",
    "    network.train()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        # До последнего слоя\n",
    "        d = network(data_in, 'central_brain')\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "                network.reward()\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "                network.punish()\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network, data, target):\n",
    "    network.eval()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 'central_brain')\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intensity2LatencyTransform:\n",
    "    def __init__(self, filter, timesteps = 15):\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.filter = filter\n",
    "        self.temporal_transform = utils.Intensity2Latency(timesteps)\n",
    "        self.cnt = 0\n",
    "    def __call__(self, image):\n",
    "        if self.cnt % 1000 == 0:\n",
    "            print(self.cnt)\n",
    "        self.cnt+=1\n",
    "        image = self.to_tensor(image) * 255\n",
    "        image.unsqueeze_(0)\n",
    "        image = self.filter(image)\n",
    "        image = sf.local_normalization(image, 8)\n",
    "        temporal_image = self.temporal_transform(image)\n",
    "        #return temporal_image.sign().byte()\n",
    "        return temporal_image.sign()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R7\n",
      "Epoch 0\n",
      "0\n",
      "Iteration 0\n",
      "Done!\n",
      "1000\n",
      "Iteration 1\n",
      "Done!\n",
      "2000\n",
      "Iteration 2\n",
      "Done!\n",
      "3000\n",
      "Iteration 3\n",
      "Done!\n",
      "4000\n",
      "Iteration 4\n",
      "Done!\n",
      "5000\n",
      "Iteration 5\n",
      "Done!\n",
      "6000\n",
      "Iteration 6\n",
      "Done!\n",
      "7000\n",
      "Iteration 7\n",
      "Done!\n",
      "8000\n",
      "Iteration 8\n",
      "Done!\n",
      "9000\n",
      "Iteration 9\n",
      "Done!\n",
      "10000\n",
      "Iteration 10\n",
      "Done!\n",
      "11000\n",
      "Iteration 11\n",
      "Done!\n",
      "12000\n",
      "Iteration 12\n",
      "Done!\n",
      "13000\n",
      "Iteration 13\n",
      "Done!\n",
      "14000\n",
      "Iteration 14\n",
      "Done!\n",
      "15000\n",
      "Iteration 15\n",
      "Done!\n",
      "16000\n",
      "Iteration 16\n",
      "Done!\n",
      "17000\n",
      "Iteration 17\n",
      "Done!\n",
      "18000\n",
      "Iteration 18\n",
      "Done!\n",
      "19000\n",
      "Iteration 19\n",
      "Done!\n",
      "20000\n",
      "Iteration 20\n",
      "Done!\n",
      "21000\n",
      "Iteration 21\n",
      "Done!\n",
      "22000\n",
      "Iteration 22\n",
      "Done!\n",
      "23000\n",
      "Iteration 23\n",
      "Done!\n",
      "24000\n",
      "Iteration 24\n",
      "Done!\n",
      "25000\n",
      "Iteration 25\n",
      "Done!\n",
      "26000\n",
      "Iteration 26\n",
      "Done!\n",
      "27000\n",
      "Iteration 27\n",
      "Done!\n",
      "28000\n",
      "Iteration 28\n",
      "Done!\n",
      "29000\n",
      "Iteration 29\n",
      "Done!\n",
      "30000\n",
      "Iteration 30\n",
      "Done!\n",
      "31000\n",
      "Iteration 31\n",
      "Done!\n",
      "32000\n",
      "Iteration 32\n",
      "Done!\n",
      "33000\n",
      "Iteration 33\n",
      "Done!\n",
      "34000\n",
      "Iteration 34\n",
      "Done!\n",
      "35000\n",
      "Iteration 35\n",
      "Done!\n",
      "36000\n",
      "Iteration 36\n",
      "Done!\n",
      "37000\n",
      "Iteration 37\n",
      "Done!\n",
      "38000\n",
      "Iteration 38\n",
      "Done!\n",
      "39000\n",
      "Iteration 39\n",
      "Done!\n",
      "40000\n",
      "Iteration 40\n",
      "Done!\n",
      "41000\n",
      "Iteration 41\n",
      "Done!\n",
      "42000\n",
      "Iteration 42\n",
      "Done!\n",
      "43000\n",
      "Iteration 43\n",
      "Done!\n",
      "44000\n",
      "Iteration 44\n",
      "Done!\n",
      "45000\n",
      "Iteration 45\n",
      "Done!\n",
      "46000\n",
      "Iteration 46\n",
      "Done!\n",
      "47000\n"
     ]
    }
   ],
   "source": [
    "kernels = [ utils.DoGKernel(3,3/9,6/9),\n",
    "            utils.DoGKernel(3,6/9,3/9),\n",
    "            utils.DoGKernel(7,7/9,14/9),\n",
    "            utils.DoGKernel(7,14/9,7/9),\n",
    "            utils.DoGKernel(13,13/9,26/9),\n",
    "            utils.DoGKernel(13,26/9,13/9)]\n",
    "filter = utils.Filter(kernels, padding = 6, thresholds = 50)\n",
    "trsf = Intensity2LatencyTransform(filter)\n",
    "\n",
    "data_root = \"data\"\n",
    "MNIST_train = utils.CacheDataset(torchvision.datasets.MNIST(root=data_root, train=True, download=True, transform = trsf))\n",
    "MNIST_test = utils.CacheDataset(torchvision.datasets.MNIST(root=data_root, train=False, download=True, transform = trsf))\n",
    "MNIST_loader = DataLoader(MNIST_train, batch_size=1000, shuffle=False)\n",
    "MNIST_testLoader = DataLoader(MNIST_test, batch_size=len(MNIST_test), shuffle=False)\n",
    "\n",
    "flyeye = FlyEye()\n",
    "if use_cuda:\n",
    "    flyeye.cuda()\n",
    "\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Training R7\n",
    "print(\"Training R7\")\n",
    "if os.path.isfile(\"saved_R7.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_R7.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'R7')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_R7.net\")\n",
    "    \n",
    "\n",
    "# Training R8\n",
    "print(\"Training R8\")\n",
    "if os.path.isfile(\"saved_R8.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_R8.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'R8')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_R8.net\")\n",
    "    \n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Training L1\n",
    "print(\"Training L1\")\n",
    "if os.path.isfile(\"saved_L1.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_L1.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'L1')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_L1.net\")\n",
    "    \n",
    "    \n",
    "# Training L2\n",
    "print(\"Training L2\")\n",
    "if os.path.isfile(\"saved_L2.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_L2.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'L2')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_L2.net\")\n",
    "    \n",
    "    \n",
    "# Training L3\n",
    "print(\"Training L3\")\n",
    "if os.path.isfile(\"saved_L3.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_L3.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'L3')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_L3.net\")\n",
    "\n",
    "# Training L4\n",
    "print(\"Training L4\")\n",
    "if os.path.isfile(\"saved_L4.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_L4.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'L4')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_L4.net\")\n",
    "\n",
    "    \n",
    "# Training L5\n",
    "print(\"Training L5\")\n",
    "if os.path.isfile(\"saved_L5.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_L5.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'L5')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_L5.net\")\n",
    "    \n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Training C2\n",
    "print(\"Training C2\")\n",
    "if os.path.isfile(\"saved_C2.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_C2.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'C2')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_C2.net\")\n",
    "    \n",
    "    \n",
    "# Training C3\n",
    "print(\"Training C3\")\n",
    "if os.path.isfile(\"saved_C3.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_C3.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'C3')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_C3.net\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Training Mi1\n",
    "print(\"Training Mi1\")\n",
    "if os.path.isfile(\"saved_Mi1.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Mi1.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Mi1')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Mi1.net\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# Training Mi4\n",
    "print(\"Training Mi4\")\n",
    "if os.path.isfile(\"saved_Mi4.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Mi4.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Mi4')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Mi4.net\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Training Mi9\n",
    "print(\"Training Mi9\")\n",
    "if os.path.isfile(\"saved_Mi9.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Mi9.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Mi9')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Mi9.net\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Training Mi15\n",
    "print(\"Training Mi15\")\n",
    "if os.path.isfile(\"saved_Mi15.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Mi15.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Mi15')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Mi15.net\")\n",
    "\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------------\n",
    "# Training Tm1\n",
    "print(\"Training Tm1\")\n",
    "if os.path.isfile(\"saved_Tm1.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Tm1.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Tm1')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Tm1.net\")\n",
    "    \n",
    "# Training Tm2\n",
    "print(\"Training Tm2\")\n",
    "if os.path.isfile(\"saved_Tm2.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Tm2.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Tm2')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Tm2.net\")\n",
    "    \n",
    "# Training Tm3\n",
    "print(\"Training Tm3\")\n",
    "if os.path.isfile(\"saved_Tm3.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Tm3.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Tm3')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Tm3.net\")\n",
    "    \n",
    "# Training Tm4\n",
    "print(\"Training Tm4\")\n",
    "if os.path.isfile(\"saved_Tm4.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Tm4.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Tm4')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Tm4.net\")\n",
    "    \n",
    "# Training Tm6\n",
    "print(\"Training Tm6\")\n",
    "if os.path.isfile(\"saved_Tm6.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Tm6.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Tm6')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Tm6.net\")\n",
    "    \n",
    "    \n",
    "# Training Tm9\n",
    "print(\"Training Tm9\")\n",
    "if os.path.isfile(\"saved_Tm9.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Tm9.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Tm9')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Tm9.net\")\n",
    "    \n",
    "# Training Tm20\n",
    "print(\"Training Tm20\")\n",
    "if os.path.isfile(\"saved_Tm20.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_Tm20.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'Tm20')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_Tm20.net\")\n",
    "    \n",
    "# Training TmY5a\n",
    "print(\"Training TmY5a\")\n",
    "if os.path.isfile(\"saved_TmY5a.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_TmY5a.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'TmY5a')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_TmY5a.net\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------------- \n",
    "# Training T2\n",
    "print(\"Training T2\")\n",
    "if os.path.isfile(\"saved_T2.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_T2.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'T2')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_T2.net\")\n",
    "\n",
    "# Training T2a  \n",
    "print(\"Training T2a\")\n",
    "if os.path.isfile(\"saved_T2a.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_T2a.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'T2a')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_T2a.net\")\n",
    "    \n",
    "# Training T3 \n",
    "print(\"Training T3\")\n",
    "if os.path.isfile(\"saved_T3.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_T3.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'T3')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_T3.net\")\n",
    "\n",
    "\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------------- \n",
    "# Training LC4\n",
    "print(\"Training LC4\")\n",
    "if os.path.isfile(\"saved_LC4.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_LC4.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'LC4')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_LC4.net\")\n",
    "\n",
    "# Training LC17  \n",
    "print(\"Training LC17\")\n",
    "if os.path.isfile(\"saved_LC17.net\"):\n",
    "    mozafari.load_state_dict(torch.load(\"saved_LC17.net\"))\n",
    "else:\n",
    "    for epoch in range(2):\n",
    "        print(\"Epoch\", epoch)\n",
    "        iter = 0\n",
    "        for data,targets in MNIST_loader:\n",
    "            print(\"Iteration\", iter)\n",
    "            train_unsupervise(flyeye, data, 'LC17')\n",
    "            print(\"Done!\")\n",
    "            iter+=1\n",
    "    torch.save(flyeye.state_dict(), \"saved_LC17.net\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------------- \n",
    "\n",
    "# initial adaptive learning rates\n",
    "\n",
    "apr = mozafari.stdp_central_brain.learning_rate[0][0].item()\n",
    "anr = mozafari.stdp_central_brain.learning_rate[0][1].item()\n",
    "app = mozafari.anti_stdp_central_brain.learning_rate[0][1].item()\n",
    "anp = mozafari.anti_stdp_central_brain.learning_rate[0][0].item()\n",
    "\n",
    "adaptive_min = 0\n",
    "adaptive_int = 1\n",
    "apr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * apr\n",
    "anr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * anr\n",
    "app_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * app\n",
    "anp_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * anp\n",
    "\n",
    "# perf\n",
    "best_train = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "best_test = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "\n",
    "# Training Central Brain\n",
    "print(\"Training Central Brain\")\n",
    "for epoch in range(10):\n",
    "    print(\"Epoch #:\", epoch)\n",
    "    perf_train = np.array([0.0,0.0,0.0])\n",
    "    for data,targets in MNIST_loader:\n",
    "        perf_train_batch = train_rl(flyeye, data, targets)\n",
    "        print(perf_train_batch)\n",
    "        #update adaptive learning rates\n",
    "        apr_adapt = apr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "        anr_adapt = anr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "        app_adapt = app * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "        anp_adapt = anp * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "        flyeye.update_learning_rates(apr_adapt, anr_adapt, app_adapt, anp_adapt)\n",
    "        perf_train += perf_train_batch\n",
    "    perf_train /= len(MNIST_loader)\n",
    "    if best_train[0] <= perf_train[0]:\n",
    "        best_train = np.append(perf_train, epoch)\n",
    "    print(\"Current Train:\", perf_train)\n",
    "    print(\"   Best Train:\", best_train)\n",
    "\n",
    "    for data,targets in MNIST_testLoader:\n",
    "        perf_test = test(flyeye, data, targets)\n",
    "        if best_test[0] <= perf_test[0]:\n",
    "            best_test = np.append(perf_test, epoch)\n",
    "            torch.save(flyeye.state_dict(), \"saved.net\")\n",
    "        print(\" Current Test:\", perf_test)\n",
    "        print(\"    Best Test:\", best_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
